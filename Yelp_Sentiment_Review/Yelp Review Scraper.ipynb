{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c858c49a",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Using BERT Neural Network\n",
    "The model being used can be found in the link provided: https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment\n",
    "\n",
    "This model is great for sentiment analysis as rather than receiving a confidence score or a number between 0 and 1, it predicts the sentiment of the review as a number of stars (between 1 and 5).\n",
    "\n",
    "Other libraries used include requests and beautifulsoup. Requests will allow us to make a request to the yelp site we will be scraping, and beautifulsoup will allow us to work through the data we receive back from requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe41d8ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d319157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd4f8ef",
   "metadata": {},
   "source": [
    "- AutoTokenizer converts a string to a sequence of numbers to be used by the NLP model.\n",
    "- AutoModelForSequenceClassification gives us the architecture from transformers to be able to load in the NLP model.\n",
    "- We are going to be using the hardmax function from torch in order to extract our highest sequence result.\n",
    "- Importing re to creating a regex function to extract the specific elements we want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe32c70",
   "metadata": {},
   "source": [
    "# 1. Instantiate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991d2ea5",
   "metadata": {},
   "source": [
    "We are going to create two variables, tokenizer and model.\n",
    "- Tokenizer - creating our tokenizer, using the .from_pretrained function to import a pretrained model and the previously imported AutoTokenizer function from transformers.\n",
    "- Model - creating our model, using the .from_pretrained function and the AutoModelForSequenceClassifcation function imported from transfomers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "188cd02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d4b5c111464fe2be1cc7303525df6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/669M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Natan\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Natan\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00c18e0",
   "metadata": {},
   "source": [
    "# 3. Encode and Calculate Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c72854",
   "metadata": {},
   "source": [
    "Here I am going to create a practice token and see if the tokenizer is working how it should:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c179df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode(\"I disliked this immensely, the worst outcome possible.\", return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6372a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,   151, 23145, 17172, 10163, 10372, 75572, 10563,   117, 10103,\n",
       "         43060, 80196, 14312,   119,   102]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6e4d0e",
   "metadata": {},
   "source": [
    "Now I will pass through the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3f90e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0d6b816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 3.0633,  2.8742,  0.5110, -2.5527, -3.1332]],\n",
       "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f11c4e9",
   "metadata": {},
   "source": [
    "### Understanding Results\n",
    "The output from the model is a one-hot encoded list of scores. The position with the highest score represents the sentiment rating. e.g [.9, .2, .1, -2,-5] is a rating of 1, as .9 is the highest value and it's in the first position."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50296b72",
   "metadata": {},
   "source": [
    "Let's try to make this something more understandable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0485c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.0633,  2.8742,  0.5110, -2.5527, -3.1332]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d7ca847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(torch.argmax(result.logits))+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e085e23",
   "metadata": {},
   "source": [
    "# 3. Collect Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208d4c8f",
   "metadata": {},
   "source": [
    "- Requests library to grab the webpage to scrape\n",
    "- We will then pass that variable off to BeautifulSoup to set our parser\n",
    "- Then we will have to specifically extract the elements from the webpage that we want.\n",
    "- The reviews are within a comment tag so we will scrape the comment classes off the webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b44ddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://www.yelp.ca/biz/seoul-fried-chicken-edmonton\")\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "regex = re.compile('.*comment.*')\n",
    "results = soup.find_all('p', {'class':regex})\n",
    "reviews = [result.text for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46287a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SFC around Whyte Ave has been one of the best Korean fried chicken places in Edmonton since they first opened. The overall quality and portion of the food for the price is unbeatable. I'd rate them 9.3/10 and recommend trying these flavours:- Garlic Soy- Curry\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4685451c",
   "metadata": {},
   "source": [
    "# 4. Load Reviews into DataFrame and Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f02730b",
   "metadata": {},
   "source": [
    "- We will first create a dataframe with the reviews we have scraped\n",
    "- We will create a function, that takes a string and passes it through the function to receive a sentiment result.\n",
    "- We will be using the tokenizer function and passing the reviews through the tensors.\n",
    "- We will be taking those tokens through the model and store them in the result function and then finally returning the sentiment score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e491030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cb0c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array(reviews), columns=['Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "791533ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SFC around Whyte Ave has been one of the best Korean fried chicken places in Edmonton since they first opened. The overall quality and portion of the food for the price is unbeatable. I'd rate them 9.3/10 and recommend trying these flavours:- Garlic Soy- Curry\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8071bd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score(review):\n",
    "    tokens = tokenizer.encode(review, return_tensors='pt')\n",
    "    result = model(tokens)\n",
    "    return int(torch.argmax(result.logits))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "783be078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_score(df['Review'].iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8a96a1",
   "metadata": {},
   "source": [
    "Now this is useful. But what if we wanted to provide these reviews en masse? And store those sentiment scores within the dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "051f3f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment'] = df['Review'].apply(lambda x: sentiment_score(x[:512]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce713886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SFC around Whyte Ave has been one of the best ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is one of the best (Korean style) fried c...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Korean fried chicken. The best when they are h...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moist moist moist!  Been a minute since we pop...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I love Seoul Fried chicken, this is a popular ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Came here for Valentine's Day take out and boy...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I've come here for take out only, a couple of ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Free parking in the strip-mall parking lot jus...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The chicken is tender and juicy! One of the be...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This was a real disappointment.  Overcooked, t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>If you are fan of fried chicken than this is p...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Crispy, perfectly seasoned fried chicken with ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Review  Sentiment\n",
       "0   SFC around Whyte Ave has been one of the best ...          4\n",
       "1   This is one of the best (Korean style) fried c...          5\n",
       "2   Korean fried chicken. The best when they are h...          5\n",
       "3   Moist moist moist!  Been a minute since we pop...          5\n",
       "4   I love Seoul Fried chicken, this is a popular ...          5\n",
       "5   Came here for Valentine's Day take out and boy...          5\n",
       "6   I've come here for take out only, a couple of ...          5\n",
       "7   Free parking in the strip-mall parking lot jus...          2\n",
       "8   The chicken is tender and juicy! One of the be...          5\n",
       "9   This was a real disappointment.  Overcooked, t...          1\n",
       "10  If you are fan of fried chicken than this is p...          4\n",
       "11  Crispy, perfectly seasoned fried chicken with ...          5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ff1f18",
   "metadata": {},
   "source": [
    "### You can use this code to scrape any Yelp review site, just change the link in the 'r' variable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118eba21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
